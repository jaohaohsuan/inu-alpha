akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = info
  log-dead-letters = 1
  log-dead-letters-during-shutdown = off

  actor {

    kryo  {
      # Possibles values for type are: graph or nograph
      # graph supports serialization of object graphs with shared nodes
      # and cyclic references, but this comes at the expense of a small overhead
      # nograph does not support object grpahs with shared nodes, but is usually faster
      type = "graph"


      # Possible values for idstrategy are:
      # default, explicit, incremental
      #
      # default - slowest and produces bigger serialized representation. Contains fully-
      # qualified class names (FQCNs) for each class
      #
      # explicit - fast and produces compact serialized representation. Requires that all
      # classes that will be serialized are pre-registered using the "mappings" and "classes"
      # sections. To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to provide exactly the same entries in the "mappings" section
      #
      # incremental - fast and produces compact serialized representation. Support optional
      # pre-registering of classes using the "mappings" and "classes" sections. If class is
      # not pre-registered, it will be registered dynamically by picking a next available id
      # To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to pre-register them using at least the "classes" section

      idstrategy = "default"

      # Define a default size for byte buffers used during serialization
      buffer-size = 4096

      # The serialization byte buffers are doubled as needed until they exceed maxBufferSize and an exception is thrown. Can be -1 for no maximum.
      max-buffer-size = -1

      # Define a default size for serializer pool
      serializer-pool-size = 16

      # If set, akka uses manifests to put a class name
      # of the top-level object into each message
      use-manifests = false

      # Enable transparent compression of serialized messages
      # accepted values are: off | lz4 | deflate
      compression = off

      # Log implicitly registered classes. Useful, if you want to know all classes
      # which are serialized
      implicit-registration-logging = false

      # If enabled, Kryo logs a lot of information about serialization process.
      # Useful for debugging and lowl-level tweaking
      kryo-trace = false

      # If enabled, Kryo uses internally a map detecting shared nodes.
      # This is a preferred mode for big object graphs with a lot of nodes.
      # For small object graphs (e.g. below 10 nodes) set it to false for
      # better performance.
      kryo-reference-map = true

      # Define mappings from a fully qualified class name to a numeric id.
      # Smaller ids lead to smaller sizes of serialized representations.
      #
      # This section is mandatory for idstartegy=explciit
      # This section is optional  for idstartegy=incremental
      # This section is ignored   for idstartegy=default
      #
      # The smallest possible id should start at 20 (or even higher), because
      # ids below it are used by Kryo internally e.g. for built-in Java and
      # Scala types
      mappings {
        # fully.qualified.classname1 = id1
        # fully.qualified.classname2 = id2
      }

      # Define a set of fully qualified class names for
      # classes to be used for serialization.
      # The ids for those classes will be assigned automatically,
      # but respecting the order of declaration in this section
      #
      # This section is optional  for idstartegy=incremental
      # This section is ignored   for idstartegy=default
      # This section is optional  for idstartegy=explicit
      classes = [
        # fully.qualified.classname2
        "domain.storedQuery.StoredQueryAggregateRoot$ItemCreated",
        "domain.storedQuery.StoredQueryAggregateRoot$ItemsChanged",
        "protocol.storedQuery.StoredQuery",
        "protocol.storedQuery.BoolClause",
        "scala.collection.immutable.Map$EmptyMap$",
        "scala.collection.immutable.Set$EmptySet$"
      ]
    }

    serializers {
      java = "akka.serialization.JavaSerializer"
      kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
    }

    serialization-bindings {
      "java.io.Serializable" = kryo
    }


    //serialize-messages = on
    //serialize-creators = on
    provider = "akka.cluster.ClusterActorRefProvider"
    debug {
      receive = off
      lifecycle = off
    }

    //warn-about-java-serializer-usage = off
  }

  remote {
    netty.tcp {
      hostname = ${clustering.ip}
      port = ${clustering.port}
    }
  }

  cluster {
    log-info = off
    auto-down-unreachable-after = 2s
    metrics.enabled = off
    metrics.native-library-extract-folder=${user.dir}/target/native
    client.receptionist {
      name = receptionist
    }
  }

  extensions = [
    "akka.cluster.metrics.ClusterMetricsExtension",
    "akka.cluster.client.ClusterClientReceptionist",
    "com.romix.akka.serialization.kryo.KryoSerializationExtension$"
  ]
}

akka.persistence {
  journal.plugin = "akka.persistence.journal.leveldb-shared"
  snapshot-store.plugin = "akka.persistence.snapshot-store.local"
  snapshot-store.local.dir = "var/leveldb/snapshots"
}

akka.persistence.query.journal.leveldb {
  # Implementation class of the LevelDB ReadJournal
  class = "akka.persistence.query.journal.leveldb.LeveldbReadJournalProvider"

  # Absolute path to the write journal plugin configuration entry that this
  # query journal will connect to. That must be a LeveldbJournal or SharedLeveldbJournal.
  # If undefined (or "") it will connect to the default journal as specified by the
  # akka.persistence.journal.plugin property.
  write-plugin = ""

  # The LevelDB write journal is notifying the query side as soon as things
  # are persisted, but for efficiency reasons the query side retrieves the events
  # in batches that sometimes can be delayed up to the configured `refresh-interval`.
  refresh-interval = 0.5s

}

akka.cluster.singleton {
  # The actor name of the child singleton actor.
  singleton-name = "singleton"

  # Singleton among the nodes tagged with specified role.
  # If the role is not specified it's a singleton among all nodes in the cluster.
  role = "compute"
}

akka.cluster.singleton-proxy {
  # The actor name of the singleton actor that is started by the ClusterSingletonManager
  singleton-name = ${akka.cluster.singleton.singleton-name}

  # The role of the cluster nodes where the singleton can be deployed.
  # If the role is not specified then any node will do.
  role = "compute"

  buffer-size = 1000
}

clustering {
  port = ${?CLUSTER_PORT}
  cluster.name = inu
}

spray.routing {
  users {
    atlas = subaru
    dev = grandsys
  }
}